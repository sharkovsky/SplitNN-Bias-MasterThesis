{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f4db1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Raffaele\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Raffaele\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raffaele\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import syft as sy\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "#import tensorflow as tf\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f3862f",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "###                                      Generation of Data      -         Synthetic Data\n",
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "050b82c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_Linear():\n",
    "    def __init__(self, N, n_chanels, image_height, image_weight):\n",
    "        self.N = N\n",
    "        self.n_chanels = n_chanels\n",
    "        self.image_height = image_height\n",
    "        self.image_weight = image_weight\n",
    "        self.noise = 0.7\n",
    "        self.data_linear = []\n",
    "    def linear_model(self, x):\n",
    "        tm = np.random.randn(3, 32, 32)\n",
    "        return x*tm\n",
    "        \n",
    "    def create(self):\n",
    "        for i in range(self.N):\n",
    "            x_class_i = np.random.randn(1, self.n_chanels, self.image_height, self.image_weight) * self.noise\n",
    "            self.data_linear.append(self.linear_model(x_class_i))\n",
    "        return torch.utils.data.TensorDataset(torch.tensor(np.vstack(self.data_linear), dtype=torch.double), torch.tensor(np.hstack(np.random.randint(2, size=self.N)), dtype=torch.double))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "141d4d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_Non_Linear():\n",
    "    def __init__(self, N, n_chanels, image_height, image_weight, c, l):\n",
    "        \n",
    "        self.N = N\n",
    "        self.n_chanels = n_chanels\n",
    "        self.image_height = image_height\n",
    "        self.image_weight = image_weight\n",
    "        self.noise = 0.9\n",
    "        self.data_non_linear = []\n",
    "        self.c = c\n",
    "        self.l = l\n",
    "        \n",
    "    def non_linear(self, x, c, l):\n",
    "        return np.exp(-(x-c)**2/l)\n",
    "        \n",
    "    def create(self):\n",
    "        for i in range(self.N):\n",
    "                    ##adding some noise\n",
    "                x_class_i = np.random.randn(1, self.n_chanels, self.image_height, self.image_weight) * self.noise\n",
    "                self.data_non_linear.append(self.non_linear(x_class_i, self.c, self.l))\n",
    "        return torch.utils.data.TensorDataset(torch.tensor(np.vstack(self.data_non_linear), dtype=torch.double), torch.tensor(np.hstack(np.random.randint(2, size=self.N)), dtype=torch.double))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac911693",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "### Clients Models\n",
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7bd30d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client1(nn.Module):\n",
    "    def __init__(self, x_train, y_train):\n",
    "        super(Client1, self).__init__()\n",
    "\n",
    "        self.num_samples = x_train.shape[0]\n",
    "        self.x_train = x_train\n",
    "        self.labels = y_train\n",
    "        self.batch = 10\n",
    "        \n",
    "        \n",
    "\n",
    "        self.encoder_model = nn.Sequential(nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(1,1), padding='valid', dtype=torch.float64),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Conv2d(32, 64, kernel_size=(3,3), stride=(1,1), padding='valid', dtype=torch.float64),\n",
    "                                    nn.ReLU()\n",
    "                                    )\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        self.latent_model = nn.Sequential(\n",
    "                                nn.Conv2d(64, 30*30, kernel_size=(3,3), stride=(1,1), padding='valid', dtype=torch.float64),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(kernel_size=(2,2)),\n",
    "                                nn.Flatten())\n",
    "        \n",
    "        self.decoder_model = nn.Sequential(nn.Linear(108900, 10, dtype=torch.float64),\n",
    "                                           nn.Softmax(dim=1))\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs_encoder = self.encoder_model(inputs)\n",
    "        outputs_latent = self.latent_model(outputs_encoder)\n",
    "        latent_parameters = list(self.latent_model.parameters())\n",
    "        outputs_class = self.decoder_model(outputs_latent)\n",
    "        return outputs_class, latent_parameters\n",
    "\n",
    "    \n",
    "    def update(self, latent_parameters):\n",
    "        # Get the parameters of the latent model\n",
    "        latent_params = self.latent_model.parameters()\n",
    "    \n",
    "        # Iterate over the parameters and update them with new values\n",
    "        for param, new_value in zip(latent_params, latent_parameters):\n",
    "            param.data.copy_(new_value)\n",
    "    \n",
    "    \n",
    "    def train_step(self, inputs, labels):\n",
    "        \n",
    "        #Forward pass\n",
    "        logits, latent_parameters = self.forward(inputs)\n",
    "\n",
    "        #Compute the loss\n",
    "        labels = labels.long()\n",
    "        loss = self.loss_function(logits, labels)\n",
    "\n",
    "        #Zero the gradients\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        #Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        #updare the parameters\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item(), latent_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2a8cdafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client2(nn.Module):\n",
    "    def __init__(self, x_train, y_train):\n",
    "        super(Client2, self).__init__()\n",
    "\n",
    "        self.num_samples = x_train.shape[0]\n",
    "        self.x_train = x_train\n",
    "        self.labels = y_train\n",
    "        self.batch = 10\n",
    "        \n",
    "        \n",
    "\n",
    "        self.encoder_model = nn.Sequential(\n",
    "                                    nn.Conv2d(3, 32, kernel_size=5, stride=1, dtype=torch.float64),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1,1), padding='valid', dtype=torch.float64),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                                    nn.ReLU())\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        self.latent_model = nn.Sequential(\n",
    "                                nn.Conv2d(64, 30*30, kernel_size=(3,3), stride=(1,1), padding='valid', dtype=torch.float64),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(kernel_size=(2,2)),\n",
    "                                nn.Flatten())\n",
    "        \n",
    "        self.decoder_model = nn.Sequential(nn.Linear(22500, 10, dtype=torch.float64),\n",
    "                                     nn.Softmax(dim=1))\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs_encoder = self.encoder_model(inputs)\n",
    "        outputs_latent = self.latent_model(outputs_encoder)\n",
    "        latent_parameters = list(self.latent_model.parameters())\n",
    "        outputs_class = self.decoder_model(outputs_latent)\n",
    "        return outputs_class, latent_parameters\n",
    "\n",
    "\n",
    "    def update(self, latent_parameters):\n",
    "        # Get the parameters of the latent model\n",
    "        latent_params = self.latent_model.parameters()\n",
    "    \n",
    "        # Iterate over the parameters and update them with new values\n",
    "        for param, new_value in zip(latent_params, latent_parameters):\n",
    "            param.data.copy_(new_value)\n",
    "    \n",
    "    def train_step(self, inputs, labels):\n",
    "        \n",
    "        #Forward pass\n",
    "        logits, latent_parameters = self.forward(inputs)\n",
    "\n",
    "        #Compute the loss\n",
    "        labels = labels.long()\n",
    "        loss = self.loss_function(logits, labels)\n",
    "\n",
    "        #Zero the gradients\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        #Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        #updare the parameters\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item(), latent_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaab5d6",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "## datasets\n",
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9de1dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Linear = data_Linear(1000, 3, 32, 32)\n",
    "dataset = data_Linear.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "777e9dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Non_Linear = data_Non_Linear(1000, 1, 28, 28, 3, 5)\n",
    "dataset_non = data_Non_Linear.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92232fe",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "## dataLoaders\n",
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7b11ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "trainloader_linear = torch.utils.data.DataLoader(X_train, batch_size=10, shuffle=True, num_workers=2)\n",
    "testloader_linear = torch.utils.data.DataLoader(X_test, batch_size=10, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfa0c435",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_n, X_test_n = train_test_split(dataset_non, test_size=0.2, random_state=42)\n",
    "\n",
    "trainloader_non_linear = torch.utils.data.DataLoader(X_train_n, batch_size=10, shuffle=True, num_workers=2)\n",
    "testloader_non_linear = torch.utils.data.DataLoader(X_test_n, batch_size=10, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "459f40f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 28, 28]) tensor([1, 0, 0, 1, 1, 1, 1, 0, 1, 0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in trainloader_non_linear:\n",
    "    print(images.shape, labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "39f7fe81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2.1612\n",
      "Epoch [1/10], Loss: 1.8611\n",
      "1\n",
      "Epoch [2/10], Loss: 1.7612\n",
      "Epoch [2/10], Loss: 1.9612\n",
      "2\n",
      "Epoch [3/10], Loss: 1.9612\n",
      "Epoch [3/10], Loss: 1.7612\n",
      "3\n",
      "Epoch [4/10], Loss: 2.0612\n",
      "Epoch [4/10], Loss: 1.9612\n",
      "4\n",
      "Epoch [5/10], Loss: 1.7612\n",
      "Epoch [5/10], Loss: 1.9612\n",
      "5\n",
      "Epoch [6/10], Loss: 2.1612\n",
      "Epoch [6/10], Loss: 1.7612\n",
      "6\n",
      "Epoch [7/10], Loss: 2.0612\n",
      "Epoch [7/10], Loss: 1.6612\n",
      "7\n",
      "Epoch [8/10], Loss: 1.9612\n",
      "Epoch [8/10], Loss: 2.1611\n",
      "8\n",
      "Epoch [9/10], Loss: 2.2612\n",
      "Epoch [9/10], Loss: 2.1611\n",
      "9\n",
      "Epoch [10/10], Loss: 2.1612\n",
      "Epoch [10/10], Loss: 1.7612\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "client1 = Client1(x_train_linear, y_train_linear)\n",
    "client2 = Client2(x_train_non_linear, y_train_non_linear)\n",
    "\n",
    "num_epochs = 10\n",
    "latent_parameters = []\n",
    "\n",
    "#training loop\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    client1.train()\n",
    "    client2.train()\n",
    "    \n",
    "    for i, ((images_linear, labels_linear), (images_non_linear, labels_non_linear)) in enumerate(zip(trainloader_linear, trainloader_non_linear)):\n",
    "        loss_1, latent_parameters_1 = client1.train_step(images_non_linear, labels_non_linear)\n",
    "        loss_2, latent_parameters_2 = client2.train_step(images_linear, labels_linear)\n",
    "        \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss_1:.4f}\")\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss_2:.4f}\")\n",
    "    if ((epoch+1) == (epoch+1)):\n",
    "        print(epoch+1)\n",
    "        latent_parameters =[(x + y) / 2 for x, y in zip(latent_parameters_1, latent_parameters_2)]\n",
    "        client1.update(latent_parameters)\n",
    "        client2.update(latent_parameters)\n",
    "    \n",
    "    latent_parameters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21cb3d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_linear = []\n",
    "y_train_linear = []\n",
    "x_test_linear = []\n",
    "y_test_linear = []\n",
    "\n",
    "for images, labels in trainloader_linear:\n",
    "    x_train_linear.append(images)\n",
    "    y_train_linear.append(labels)\n",
    "    \n",
    "for images_test, labels_test in testloader_linear:\n",
    "    x_test_linear.append(images_test)\n",
    "    y_test_linear.append(labels_test)\n",
    "\n",
    "# Concatenate the batches to obtain the full datasets\n",
    "x_train_linear = torch.cat(x_train_linear, dim=0)\n",
    "y_train_linear = torch.cat(y_train_linear, dim=0)\n",
    "\n",
    "x_test_linear = torch.cat(x_test_linear, dim=0)\n",
    "y_test_linear = torch.cat(y_test_linear, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89c59606",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_non_linear = []\n",
    "y_train_non_linear = []\n",
    "x_test_non_linear = []\n",
    "y_test_non_linear = []\n",
    "\n",
    "for images, labels in trainloader_non_linear:\n",
    "    x_train_non_linear.append(images)\n",
    "    y_train_non_linear.append(labels)\n",
    "    \n",
    "for images_test, labels_test in testloader_non_linear:\n",
    "    x_test_non_linear.append(images_test)\n",
    "    y_test_non_linear.append(labels_test)\n",
    "\n",
    "# Concatenate the batches to obtain the full datasets\n",
    "x_train_non_linear = torch.cat(x_train_non_linear, dim=0)\n",
    "y_train_non_linear = torch.cat(y_train_non_linear, dim=0)\n",
    "\n",
    "x_test_non_linear = torch.cat(x_test_non_linear, dim=0)\n",
    "y_test_non_linear = torch.cat(y_test_non_linear, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e109eaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.47999998927116394, 0.5149999856948853)\n"
     ]
    }
   ],
   "source": [
    "def test(inputs_1, labels_1, inputs_2, labels_2):\n",
    "        logits_1, _ = client1.forward(inputs_1)\n",
    "        logits_2, _ = client2.forward(inputs_2)\n",
    "        \n",
    "\n",
    "        _, predictions_1 = torch.max(logits_1, 1)\n",
    "        _, predictions_2 = torch.max(logits_2, 1)\n",
    "        \n",
    "        acc_1 = torch.mean((predictions_1 == labels_1).float())\n",
    "        acc_2 = torch.mean((predictions_2 == labels_2).float())\n",
    "\n",
    "        return acc_1.item(), acc_2.item() \n",
    "print(test(x_test_non_linear, y_test_non_linear, x_test_linear, y_test_linear))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
