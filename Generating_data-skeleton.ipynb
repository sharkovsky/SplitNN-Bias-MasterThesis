{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4db1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc0103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42424242)\n",
    "np.random.seed(42424242)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f3862f",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "###                                      Generation of Data      -         Synthetic Data\n",
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368a862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the (latent) gaussians\n",
    "mus = (np.array([-2., -2.]), np.array([2., 2.]))\n",
    "covs = (\n",
    "    np.array([[0.5, 0.],[0., 0.5]]),\n",
    "    np.array([[0.3, 0.1], [0.1, 0.3]]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d4446",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 2\n",
    "n_classes = len(mus)\n",
    "n_samples_per_class = 500\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for i in range(n_classes):\n",
    "    features.append(\n",
    "        np.random.multivariate_normal(mean=mus[i], \n",
    "                                      cov=covs[i],\n",
    "                                      size=(n_samples_per_class,))\n",
    "    )\n",
    "    labels.append([i]*n_samples_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53349b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_orig = np.array(features).reshape(n_classes*n_samples_per_class, n_features)\n",
    "labels_orig = np.array(labels).reshape(n_classes*n_samples_per_class, 1).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d425e70",
   "metadata": {},
   "source": [
    "## View latent dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa34ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    features_orig[:,0], features_orig[:,1], c=labels_orig\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76ede42",
   "metadata": {},
   "source": [
    "## Warp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb85f4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_simple_warp_functions = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dd8fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difficult warp functions\n",
    "def warp1(a):\n",
    "    x = a[:,0]\n",
    "    y = a[:,1]\n",
    "    out1 = x*y\n",
    "    out2 = x + np.exp(-y/10.)\n",
    "    out3 = (np.log(x*x*y*y) + 10*x*x*y - x)/100.\n",
    "    return np.stack((out1, out2, out3), axis=-1)\n",
    "\n",
    "def warp2(a):\n",
    "    x = a[:,0]\n",
    "    y = a[:,1]\n",
    "    out1 = np.log(x*x*y*y) + 10*x*y*np.sin(x)\n",
    "    out2 = y - 10*x*y\n",
    "    out3 = x*y*np.tan(y)\n",
    "    out4 = np.sin(x)-np.cos(y)\n",
    "    return np.stack((out1, out2, out3, out4), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f2ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpler warp functions\n",
    "if use_simple_warp_functions:\n",
    "    def warp1(a):\n",
    "        x = a[:,0]\n",
    "        y = a[:,1]\n",
    "        out1 = x + y\n",
    "        out2 = 10*x\n",
    "        out3 = y - x\n",
    "        return np.stack((out1, out2, out3), axis=-1)\n",
    "\n",
    "    def warp2(a):\n",
    "        x = a[:,0]\n",
    "        y = a[:,1]\n",
    "        out1 = y - 5*x\n",
    "        out2 = 10*y\n",
    "        out3 = y + x*x\n",
    "        out4 = x + y\n",
    "        return np.stack((out1, out2, out3, out4), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaddfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "warping_fns = [\n",
    "    warp1,\n",
    "    warp2\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcceb902",
   "metadata": {},
   "source": [
    "## Split data among clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c921694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36da449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clients = 2\n",
    "n_samples_per_client = n_samples_per_class*n_classes//n_clients\n",
    "from sklearn.utils import shuffle\n",
    "features_orig, labels_orig = shuffle(features_orig, labels_orig)\n",
    "client_datasets = []\n",
    "for i_client in range(n_clients-1):\n",
    "    client_datasets.append(\n",
    "        TensorDataset(torch.tensor(\n",
    "            warping_fns[i_client](features_orig[i_client*n_samples_per_client:(i_client+1)*n_samples_per_client,:]),\n",
    "            dtype=torch.float32),\n",
    "         torch.tensor(labels_orig[i_client*n_samples_per_client:(i_client+1)*n_samples_per_client])\n",
    "        )\n",
    "    )\n",
    "i_client += 1\n",
    "client_datasets.append(\n",
    "    TensorDataset(torch.tensor(warping_fns[i_client](features_orig[i_client*n_samples_per_client:,:]),\n",
    "                              dtype=torch.float32),\n",
    "     torch.tensor(labels_orig[i_client*n_samples_per_client:])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a4564a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39f7809a",
   "metadata": {},
   "source": [
    "## View dataset for client 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c4a725",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_datasets[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd58158",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(10,3))\n",
    "features_np = client_datasets[0].tensors[0].numpy()\n",
    "labels_np = client_datasets[0].tensors[1].numpy()\n",
    "ax[0].scatter(\n",
    "    features_np[:,0], features_np[:,1], c=labels_np\n",
    ")\n",
    "ax[1].scatter(\n",
    "    features_np[:,0], features_np[:,2], c=labels_np\n",
    ")\n",
    "ax[2].scatter(\n",
    "    features_np[:,1], features_np[:,2], c=labels_np\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5287c01",
   "metadata": {},
   "source": [
    "## View dataset for client 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c3a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,3,figsize=(10,6))\n",
    "features_np = client_datasets[1].tensors[0].numpy()\n",
    "labels_np = client_datasets[1].tensors[1].numpy()\n",
    "ax[0][0].scatter(\n",
    "    features_np[:,0], features_np[:,1], c=labels_np\n",
    ")\n",
    "ax[0][1].scatter(\n",
    "    features_np[:,0], features_np[:,2], c=labels_np\n",
    ")\n",
    "ax[0][2].scatter(\n",
    "    features_np[:,0], features_np[:,3], c=labels_np\n",
    ")\n",
    "ax[1][0].scatter(\n",
    "    features_np[:,1], features_np[:,2], c=labels_np\n",
    ")\n",
    "ax[1][1].scatter(\n",
    "    features_np[:,1], features_np[:,3], c=labels_np\n",
    ")\n",
    "ax[1][2].scatter(\n",
    "    features_np[:,2], features_np[:,3], c=labels_np\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef78b5e5",
   "metadata": {},
   "source": [
    "## Definition of clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1156a159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aecee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client(nn.Module):\n",
    "    def __init__(self, encoder_model):\n",
    "        super(Client, self).__init__()\n",
    "        \n",
    "        self.encoder_model = encoder_model\n",
    "    \n",
    "        self.latent_model = nn.Sequential(\n",
    "                                nn.Linear(10,5),\n",
    "                                nn.Linear(5,2)\n",
    "                                 )\n",
    "    \n",
    "        self.decoder_model = nn.Sequential(nn.Linear(2,4), \n",
    "                                           nn.Linear(4,2))\n",
    "        \n",
    "        self.optimizer = torch.optim.SGD(self.parameters(), lr=0.001)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs_encoder = self.encoder_model(inputs)\n",
    "        outputs_latent = self.latent_model(outputs_encoder)\n",
    "        outputs_class = self.decoder_model(outputs_latent)\n",
    "        #print(f\"Outputs: {outputs_class}\")\n",
    "        return outputs_class\n",
    "    \n",
    "    def get_latent_space(self, inputs):\n",
    "        self.eval()\n",
    "        outputs_encoder = self.encoder_model(inputs)\n",
    "        return self.latent_model(outputs_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883f2d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_models = [\n",
    "    nn.Sequential(\n",
    "        nn.Linear(3,20),\n",
    "        nn.Linear(20,10)\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "        nn.Linear(4,30),\n",
    "        nn.Linear(30,10)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21980bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = [Client(encoder_model=e) for e in encoder_models]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5df0d1",
   "metadata": {},
   "source": [
    "## DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30787581",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "shuffle = True\n",
    "loaders = [DataLoader(dataset=d, batch_size=batch_size, shuffle=shuffle) for d in client_datasets]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df85767",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068d0b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_num_samples = np.sum([len(d) for d in client_datasets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bc5990",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1f0591",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn(\n",
    "    torch.tensor([[1., 0.]]),\n",
    "    torch.tensor([[1., 0.]])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea062fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do one \"dummy\" Federated Averaging to ensure latent models are the same\n",
    "new_state_dict = dict()\n",
    "weights = [len(d)/tot_num_samples for d in client_datasets]\n",
    "for param_name, params in clients[0].latent_model.state_dict().items():\n",
    "    avg_params = weights[0]*params.detach()\n",
    "    for client_, weight_ in zip(clients[1:], weights[1:]):\n",
    "        avg_params = avg_params + weight_*client_.latent_model.state_dict()[param_name].detach()\n",
    "    new_state_dict[param_name] = avg_params\n",
    "for client_ in clients:\n",
    "    client_.latent_model.load_state_dict(new_state_dict)\n",
    "\n",
    "print(f\"After FedAVG {[client_.latent_model.state_dict()['0.weight'][0][:1] for client_ in clients]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9ef153",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_fedavg = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efee9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs_per_round = 2\n",
    "num_rounds = 100\n",
    "losses = [[] for c in clients]\n",
    "for round_ in range(1,num_rounds+1):\n",
    "    #print(f\"Before Training {[client_.latent_model.state_dict()['0.weight'][0][:1] for client_ in clients]}\")\n",
    "    \n",
    "    for i_client, (client_, loader_) in enumerate(zip(clients, loaders)):\n",
    "        client_.train()\n",
    "        for epoch_ in range(1,num_epochs_per_round+1):\n",
    "            avg_loss = 0.\n",
    "            loader_iter = iter(loader_)\n",
    "            for data, label in loader_iter:\n",
    "                client_.optimizer.zero_grad()\n",
    "                #print(f\":: data {data} :: label {label}\")\n",
    "                prediction = client_.forward(data)\n",
    "                #print(f\":: pred {prediction}\")\n",
    "                ## convert label to logits-like tensor\n",
    "                target = torch.zeros_like(prediction, dtype=torch.float32)\n",
    "                for i, label_idx in enumerate(label):\n",
    "                    target[i,label_idx] = 1.\n",
    "                loss = loss_fn(prediction, target)\n",
    "                #print(f\":: target {target}\")\n",
    "                #print(f\":: loss {loss}\")\n",
    "                loss.backward()\n",
    "                client_.optimizer.step()\n",
    "                avg_loss += loss.detach()\n",
    "            avg_loss /= len(loader_)\n",
    "            #print(f\"Client {i_client} Epoch {epoch_} Average Loss {avg_loss}\")\n",
    "            losses[i_client].append(avg_loss)\n",
    "                \n",
    "    #print(f\"Before FedAVG {[client_.latent_model.state_dict()['0.weight'][0][:1] for client_ in clients]}\")\n",
    "            \n",
    "    # Federated Averaging\n",
    "    if do_fedavg:\n",
    "        new_state_dict = dict()\n",
    "        weights = [len(d)/tot_num_samples for d in client_datasets]\n",
    "        for param_name, params in clients[0].latent_model.state_dict().items():\n",
    "            avg_params = weights[0]*params.detach()\n",
    "            for client_, weight_ in zip(clients[1:], weights[1:]):\n",
    "                avg_params = avg_params + weight_*client_.latent_model.state_dict()[param_name].detach()\n",
    "            new_state_dict[param_name] = avg_params\n",
    "        for client_ in clients:\n",
    "            client_.latent_model.load_state_dict(new_state_dict)\n",
    "        \n",
    "    #print(f\"After FedAVG {[client_.latent_model.state_dict()['0.weight'][0][:1] for client_ in clients]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f679c774",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses[0], label='client 1')\n",
    "plt.plot(losses[1], label='client 2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9214624",
   "metadata": {},
   "source": [
    "## Plot latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd0726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, n_clients, figsize=(14,6))\n",
    "for i, ax in enumerate(axs):\n",
    "    client_ = clients[i]\n",
    "    client_.eval()\n",
    "    dataset = client_datasets[i]\n",
    "    latent_space = []\n",
    "    labels = []\n",
    "    for idata in range(len(dataset)):\n",
    "        data, label = dataset[idata]\n",
    "        latent_space.append(client_.get_latent_space(data).detach().numpy())\n",
    "        labels.append(label)\n",
    "    latent_space = np.array(latent_space)\n",
    "    ax.scatter(latent_space[:,0], latent_space[:,1], c=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f9d287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
