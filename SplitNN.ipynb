{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97d61573",
   "metadata": {},
   "source": [
    "    SplitNN with two partecipants:\n",
    "\n",
    "        - Bob has labels.\n",
    "        - Alice has X values.\n",
    "\n",
    "     Has two model segments:\n",
    "        - Alice has the bottom half.\n",
    "        - Bob has the top half.\n",
    "     Trains on the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92543ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Raffaele\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import syft as sy\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "#hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af15beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "train_subset = Subset(train_dataset, range(1000))\n",
    "test_subset = Subset(test_dataset, range(100))\n",
    "\n",
    "batch_size = 10\n",
    "train_loader = DataLoader(dataset=train_subset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_subset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f803ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    # Check the shape of the batch of images\n",
    "    print(images.shape)\n",
    "    break  \n",
    "\n",
    "#torch.Size([64, 1, 28, 28])  --> torch.Size([batch_size, channels, height, width])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1bd9cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client(nn.Module):\n",
    "    def __init__(self, x_train, y_train):\n",
    "        super(Client, self).__init__()\n",
    "\n",
    "        self.num_samples = x_train.shape[0]\n",
    "        self.x_train = x_train\n",
    "        self.labels = y_train\n",
    "        self.batch_size = 64\n",
    "        \n",
    "        self.model = nn.Sequential(nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding='valid'),\n",
    "                                   nn.ReLU())\n",
    "\n",
    "        self.optimizer = optim.SGD(self.parameters(), lr=1e-2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.model(inputs)\n",
    "        return outputs\n",
    "\n",
    "    def send(self, i):\n",
    "        start, end = i*self.batch_size, (i+1) * self.batch_size\n",
    "        \n",
    "        logits = self.forward(self.x_train[start:end])\n",
    "        labels = self.labels[start:end]\n",
    "        return logits, labels\n",
    "\n",
    "    def update(self, g_client, loss):\n",
    "        self.optimizer.zero_grad()\n",
    "        g_client = g_client.squeeze(dim=0).clone()\n",
    "        last = list(self.model.parameters())[-2]\n",
    "        for param, grad in zip(list(last), g_client):\n",
    "            if param is not None:\n",
    "                param -= grad * 1e-2 \n",
    "        \n",
    "        torch.autograd.grad(loss, self.model.parameters())\n",
    "\n",
    "        # Perform the backward pass starting from the gradients received from the server\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Clear the computed gradients\n",
    "        self.optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "353520a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server(nn.Module):\n",
    "    def __init__(self, client):\n",
    "        super(Server, self).__init__()\n",
    "\n",
    "        self.num_samples = client.num_samples\n",
    "        self.client = client\n",
    "        self.batch_size = client.batch_size\n",
    "        \n",
    "        self.model = nn.Sequential(nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding='valid'),\n",
    "                                   #I need to stop here with grad\n",
    "                                   \n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "                                   nn.Flatten(),\n",
    "                                   nn.Linear(64 * 12 * 12, 10),\n",
    "                                   nn.Softmax(dim=1))\n",
    "\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.SGD(self.parameters(), lr=1e-2)\n",
    "\n",
    "    def forward(self, split_logits):\n",
    "        return self.model(split_logits)\n",
    "\n",
    "    def loss(self, logits, labels):\n",
    "        return self.loss_function(logits, labels)\n",
    "\n",
    "    def train(self):\n",
    "        #g_client_accumulated = []\n",
    "\n",
    "        for i in range(self.num_samples // self.batch_size):\n",
    "            self.optimizer.zero_grad()\n",
    "            self.client.optimizer.zero_grad()\n",
    "\n",
    "            logits, labels = self.client.send(i)\n",
    "            final_logits = self.forward(logits)\n",
    "            loss = self.loss(final_logits, labels)\n",
    "\n",
    "            # Backward pass for the main model\n",
    "            g_server = torch.autograd.grad(loss, list(self.parameters())[:-1], retain_graph=True)\n",
    "            for param, grad in zip(self.parameters(), g_server):\n",
    "                param.grad = grad\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            last_layer_params_server = list(self.model.parameters())\n",
    "            #g_server_last_layer = torch.autograd.grad(loss, last_layer_params_server[0])\n",
    "            self.optimizer.step()\n",
    "            # Here I'm sending the gradients of the last layer from the server to the client\n",
    "            #self.client.update(g_server_last_layer)\n",
    "\n",
    "            # Backward pass for the client model\n",
    "            #g_client = torch.autograd.grad(loss, self.client.parameters())\n",
    "            #for param, grad in zip(self.client.parameters(), g_client):\n",
    "                #param.grad = grad\n",
    "\n",
    "            # Apply gradients for both models\n",
    "            #self.client.optimizer.step()\n",
    "\n",
    "            #g_client_accumulated.extend(g_client)\n",
    "\n",
    "        return last_layer_params_server[0], loss\n",
    "        \n",
    "\n",
    "    def test(self, inputs, labels):\n",
    "        split_logits = self.client.forward(inputs)\n",
    "        logits = self.forward(split_logits)\n",
    "\n",
    "        _, predictions = torch.max(logits, 1)\n",
    "        acc = torch.mean((predictions == labels).float())\n",
    "\n",
    "        return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "205d4d41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Output 0 of UnbindBackward0 is a view and is being modified inplace. This view is the output of a function that returns multiple views. Such functions do not allow the output views to be modified inplace. You should replace the inplace operation by an out-of-place one.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - TEST ACCURACY: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 36\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[46], line 30\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m g_client, loss \u001b[38;5;241m=\u001b[39m server\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#print(g_client[0].shape)\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m client\u001b[38;5;241m.\u001b[39mupdate(g_client, loss)\n\u001b[0;32m     32\u001b[0m test_acc \u001b[38;5;241m=\u001b[39m server\u001b[38;5;241m.\u001b[39mtest(x_test, y_test)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRound \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - TEST ACCURACY: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[45], line 32\u001b[0m, in \u001b[0;36mClient.update\u001b[1;34m(self, g_client, loss)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param, grad \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mlist\u001b[39m(last), g_client):\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 32\u001b[0m         param \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m grad \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1e-2\u001b[39m \n\u001b[0;32m     34\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Perform the backward pass starting from the gradients received from the server\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Output 0 of UnbindBackward0 is a view and is being modified inplace. This view is the output of a function that returns multiple views. Such functions do not allow the output views to be modified inplace. You should replace the inplace operation by an out-of-place one."
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    x_train.append(images)\n",
    "    y_train.append(labels)\n",
    "    \n",
    "for images_test, labels_test in test_loader:\n",
    "    x_test.append(images_test)\n",
    "    y_test.append(labels_test)\n",
    "\n",
    "# Concatenate the batches to obtain the full datasets\n",
    "x_train = torch.cat(x_train, dim=0)\n",
    "y_train = torch.cat(y_train, dim=0)\n",
    "\n",
    "x_test = torch.cat(x_test, dim=0)\n",
    "y_test = torch.cat(y_test, dim=0)\n",
    "\n",
    "def main():\n",
    "    client = Client(x_train, y_train)\n",
    "    server = Server(client)\n",
    "\n",
    "    num_rounds = 5\n",
    "    for i in range(num_rounds):\n",
    "        \n",
    "        g_client, loss = server.train()\n",
    "        #print(g_client[0].shape)\n",
    "        client.update(g_client, loss)\n",
    "        \n",
    "        test_acc = server.test(x_test, y_test)\n",
    "        print(f\"Round {i+1} - TEST ACCURACY: {test_acc * 100:.2f}%\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66814762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39058fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643a1d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec478b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ef6a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21219dba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d92d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
